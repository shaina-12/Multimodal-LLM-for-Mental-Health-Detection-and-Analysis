# Multimodal-LLM-for-Mental-Health-Detection-and-Analysis (Original)

## Authors

### Chayan Tank
### Mahisha R.
### Sarthak Pol
### Shaina Mehta
### Sonik Sandip Sarungale
### Vinayak Katoch

## Submitted To

### Dr. Rajiv Ratn Shah

## About the Project

In the $21^{st}$ century, a large number of people around the world are suffering from various mental health issues which hamper their physical and social well-being. They are traditionally diagnosed using several questionnaires, which are quite subjective and often lead to misdiagnosis. Also, several cases are left undiagnosed due to social stigma and financial issues. This project aims to leverage the use of the Multi-modal Large Language Model for the assessment of the mental state of the patient using his multimedia data by fine-tuning the LTU-AS model proposed by Gong et al. on E-DAIC (Extended Distress Analysis Interview Corpus Wizard of Oz) dataset presented in AVEC 2019 challenge as well as on our custom dataset OSDVD (Open Source depression video dataset). The evaluation shows that modified LTU-AS model is performed better than all other evaluation metrics on E-DAIC dataset as well as on OS-DVD dataset interms most of the classification matrics in which we have evaluated than simple text based LLAMA-2 7 Billion model whether it is finetuned or not. This shows that wide scope of usuage of multi-modal LLMs in mental health recognition task.

## Individual Contribution to the Work

### Chayan Tank -
### Mahisha R. -
### Sarthak Pol -
### Shaina Mehta -
### Sonik Sandip Sarungale -
### Vinayak Katoch -

## Useful Links

**Link of Baseline Results: https://github.com/shaina-12/Multimodal-LLM-for-Mental-Health-Detection-and-Analysis/tree/baseline**

**Link of Mid Project Review: https://github.com/shaina-12/Multimodal-LLM-for-Mental-Health-Detection-and-Analysis/tree/mid-review**

**Link of Final Deliverables: https://github.com/shaina-12/Multimodal-LLM-for-Mental-Health-Detection-and-Analysis/tree/final_submission**

## References and Bibliography
