# Multimodal-LLM-for-Mental-Health-Detection-and-Analysis

## Authors

### Chayan Tank
### Mahisha R.
### Sarthak Pol
### Shaina Mehta
### Sonik Sandip Sarungale
### Vinayak Katoch

## Submitted To

### Dr. Rajiv Ratn Shah

## About the Project

In the $21^{st}$ century, a large number of people around the world are suffering from various mental health issues which hamper their physical and social well-being. They are traditionally diagnosed using several questionnaires, which are quite subjective and often lead to misdiagnosis. Also, several cases are left undiagnosed due to social stigma and financial issues. This project aims to leverage the use of the Multi-modal Large Language Model for the assessment of the mental state of the patient using his multimedia data by fine-tuning the LTU-AS model proposed by Gong et al. on E-DAIC (Extended Distress Analysis Interview Corpus Wizard of Oz) dataset presented in AVEC 2019 challenge as well as on our custom dataset OSDVD (Open Source depression video dataset). The evaluation shows that modified LTU-AS model is performed better than all other evaluation metrics on E-DAIC dataset as well as on OS-DVD dataset interms most of the classification matrics in which we have evaluated than simple text based LLAMA-2 7 Billion model whether it is finetuned or not. This shows that wide scope of usuage of multi-modal LLMs in mental health recognition task.

## Youtube Video Link: 

https://www.youtube.com/watch?v=u-5ni9BytpY

## Individual Contribution to the Work

Everyone has contributed equally.

## Useful Links

**Link of Baseline Results: https://github.com/shaina-12/Multimodal-LLM-for-Mental-Health-Detection-and-Analysis/tree/baseline**

**Link of Mid Project Review: https://github.com/shaina-12/Multimodal-LLM-for-Mental-Health-Detection-and-Analysis/tree/mid-review**

**Link of Final Deliverables: https://github.com/shaina-12/Multimodal-LLM-for-Mental-Health-Detection-and-Analysis/tree/final_submission**

## References and Bibliography

[1] [n. d.]. Mental disorders. https://www.who.int/news-room/fact-sheets/detail/mental-disorders

[2] Avinash Anand, Chayan Tank, Sarthak Pol, Vinayak Katoch, Shaina Mehta, and Rajiv Ratn Shah. 2024. Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities. http://arxiv.org/abs/2407.06125 arXiv:2407.06125 [cs].

[3] Pınar Baki, Heysem Kaya, Elvan Çiftçi, Hüseyin Güleç, and Albert Ali Salah. 2022. A Multimodal Approach for Mania Level Prediction in Bipolar Disorder. IEEE Transactions on Affective Computing 13, 4 (Oct. 2022), 2119–2131. https: //doi.org/10.1109/TAFFC.2022.3193054 Conference Name: IEEE Transactions on Affective Computing.

[4] David DeVault, Ron Artstein, Grace Benn, Teresa Dey, Ed Fast, Alesia Gainer, Kallirroi Georgila, Jon Gratch, Arno Hartholt, Margaux Lhommet, Gale Lucas, Stacy Marsella, Fabrizio Morbini, Angela Nazarian, Stefan Scherer, Giota Stratou, Apar Suri, David Traum, Rachel Wood, Yuyu Xu, Albert Rizzo, and Louis-Philippe Morency. 2014. SimSensei kiosk: a virtual human interviewer for healthcare decision support. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems (AAMAS ’14). International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 1061–1068.

[5] Yuan Gong, Alexander H. Liu, Hongyin Luo, Leonid Karlinsky, and James Glass. 2023. Joint Audio and Speech Understanding. https://doi.org/10.48550/arXiv. 2309.14405 arXiv:2309.14405 [cs, eess].

[6] Jonathan Gratch, Ron Artstein, Gale Lucas, Giota Stratou, Stefan Scherer, Angela Nazarian, Rachel Wood, Jill Boberg, David DeVault, Stacy Marsella, David Traum, Skip Rizzo, and Louis-Philippe Morency. [n. d.]. The Distress Analysis Interview Corpus of human and computer interviews. ([n. d.]).

[7] Raja Kumar, Kishan Maharaj, Ashita Saxena, and Pushpak Bhattacharyya. 2024. Mental Disorder Classification via Temporal Representation of Text. http: //arxiv.org/abs/2406.15470 arXiv:2406.15470 [cs].

[8] David E. Losada and Fabio Crestani. 2016. A Test Collection for Research on Depression and Language Use. https://doi.org/10.1007/978-3-319-44564-9_3

[9] David E Losada, Fabio Crestani, and Javier Parapar. [n. d.]. Overview of eRisk at CLEF 2019 Early Risk Prediction on the Internet (extended overview). ([n. d.]).

[10] David E. Losada, Fabio Crestani, and Javier Parapar. 2018. Overview of eRisk: Early Risk Prediction on the Internet. https://doi.org/10.1007/978-3-319-98932-7_30

[11] David E. Losada, Fabio Crestani, and Javier Parapar. 2019. Overview of eRisk 2019 Early Risk Prediction on the Internet. https://doi.org/10.1007/978-3-030-28577-7_27

[12] Anupama Ray, Siddharth Kumar, Rutvik Reddy, Prerana Mukherjee, and Ritu Garg. 2019. Multi-level Attention Network using Text, Audio and Video for Depression Prediction. In Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop (AVEC ’19). Association for Computing Machinery, New York, NY, USA, 81–88. https://doi.org/10.1145/3347320.3357697

[13] Fabien Ringeval, Björn Schuller, Michel Valstar, Nicholas Cummins, Roddy Cowie, Leili Tavabi, Maximilian Schmitt, Sina Alisamir, Shahin Amiriparian, Eva-Maria Messner, Siyang Song, Shuo Liu, Ziping Zhao, Adria Mallol-Ragolta, Zhao Ren, Mohammad Soleymani, and Maja Pantic. 2019. AVEC 2019 Workshop and Challenge: State-of-Mind, Detecting Depression with AI, and Cross-Cultural Affect Recognition. In Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop (AVEC ’19). Association for Computing Machinery, New York, NY, USA, 3–12. https://doi.org/10.1145/3347320.3357688

[14] Misha Sadeghi, Bernhard Egger, Reza Agahi, Robert Richer, Klara Capito, Lydia Helene Rupp, Lena Schindler-Gmelch, Matthias Berking, and Bjoern M. Eskofier. 2023. Exploring the Capabilities of a Language Model-Only Approach for Depression Detection in Text Data. In 2023 IEEE EMBS International Conference on Biomedical and Health Informatics (BHI). 1–5. https://doi.org/10.1109/BHI58575. 2023.10313367 ISSN: 2641-3604.

[15] Wesley Ramos dos Santos and Ivandre Paraboni. 2024. Prompt-based mental health screening from social media text. http://arxiv.org/abs/2401.05912 arXiv:2401.05912 [cs].

[16] Xiangyu Zhang, Hexin Liu, Kaishuai Xu, Qiquan Zhang, Daijiao Liu, Beena Ahmed, and Julien Epps. 2024. When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection. http://arxiv.org/abs/2402.13276 arXiv:2402.13276 [cs, eess].

[17] Elvan Çiftçi, Heysem Kaya, Hüseyin Güleç, and Albert Ali Salah. 2018. The Turkish Audio-Visual Bipolar Disorder Corpus. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia). 1–6. https://doi.org/ 10.1109/ACIIAsia.2018.8470362 Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009
